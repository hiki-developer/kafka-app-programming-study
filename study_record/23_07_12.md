## 스터디 기록 (23.07.12)
---
### ❓ 질문  
건 : db 컨슈머가 토픽을 빠르게 병렬로 가져가고 싶다면 파티션을 2개 생성하여 프로듀서에서 적절히 2개의 파티션으로 데이터를 분산 전송을 하면 되는 걸까?  
- 파티션은 데이터의 순서를 보장하는 단위이기 때문에, 동일한 파티션 내에서는 순서가 보장되지만, 다른 파티션 간의 순서는 보장되지 않는다.
- ~~질문의 의도대로 진행하는 것은 좀 더 고려해봐야 할 문제이다.~~
- ~~대신 파티션 수를 컨슈머의 수와 일치하도록 조정하는 것이 좋다. 2개의 파티션을 생성하고 컨슈머 2개가 각각의 파티션에서 데이터를 소비할 수 있기 때문에 병렬 처리가 가능하다.~~
- 따라서 데이터의 순서가 중요하지 않다면 여러 파티션으로 분산 저장을 한 뒤 하나의 컨슈머가 병렬 처리를 통해 데이터를 컨슘하면 속도를 향상시킬 수 있다.

---
### 🤔 어려웠던 개념
건 : 페이지 캐시와 힙 메모리 사이 관계?  
- jvm 위에서 동작하는 카프카 브로커가 페이지 캐시를 사용하지 않는다면 지금과 같이 빠른 동작을 기대할 수 없다. 페이지 캐시를 사용하지 않으면 카프카에서 캐시를 직접 구현해야 했을 것이고, 지속적으로 변경되는 데이터 때문에 가비지 컬렉션이 자주 일어나 속도가 현저히 느려질 것이기 때문이다. 이러한 특징 때문에 카프카 브로커를 실행하는데 힙 메모리 사이즈를 크게 설정할 필요가 없다.
<br>

권재 : 람다 아키텍처에 대한 이해가 어렵네요.  
 `람다 아키텍처`  
- **레거시 데이터 수집 플랫폼을 개선하기 위해 구성한 아키텍처이다.** 초기 빅데이터 플랫폼은 엔드 투 엔드로 각 서비스 애플리케이션으로부터 데이터를 배치로 모았다. **데이터를 배치로 모으는 구조는 유연하지 못했으며 실시간으로 생성되는 데이터들에 대한 인사이트를 서비스 애플리케이션에 빠르게 전달하지 못하는 단점이 있었다.** 또한, 원천 데이터로부터 파생된 **데이터의 히스토리를 파악하기가 어려웠고** 계속되는 데이터의 가공으로 인해 **데이터가 파편화**되면서 데이터 거버넌스(데이터 표준 및 정책)를 지키기 어려웠다. 이를 해결하기 위해 배치 데이터를 처리하는 부분 외에 스피드 레이어라고 불리는 실시간 데이터 ETL 작업 영역을 정의한 아키텍처를 만들었는데, 이것이 람다 아키텍처이다.  
- 배치 레이어는 배치 데이터를 모아서 특정 시간, 타이밍마다 일괄 처리한다.  
- 서빙 레이어는 가공된 데이터를 데이터 사용자, 서비스 애플리케이션이 사용할 수 있도록 데이터가 저장된 공간이다.  
- 스피드 레이어는 서비스에서 생성되는 원천 데이터를 실시간으로 분석하는 용도로 사용한다.  
    - 카프카는 스피드 레이어에 위치한다. 서비스 애플리케이션들의 실시간 데이터를 짧은 지연시간으로 처리, 분석 할 수 있기 때문이다.
 
`카파 아키텍처`  
- 람다 아키텍처와 유사하지만 배치 레이어를 제거하고 모든 데이터를 스피드 레이어에 넣어서 처리한다는 점이 다르다. 람다 아키텍처는 레이어가 2개로 나뉘기 때문에 생기는 단점이 있다. 데이터를 분석, 처리하는 데에 필요한 로직이 2벌로 각각의 레이어에 따로 존재해야 한다는 점과 배치 데이터와 실시간 데이터를 융합하여 처리할 때는 다소 유연하지 못한 파이프라인을 생성해야 한다는 점이다.
    - `제이 크렙스`가 제안한 아키텍처
- 그런데 스피드 레이어에서 모든 데이터를 처리하므로 서비스에서 생성되는 모든 종류의 데이터를 스트림 처리해야 했다. 배치 데이터를 어떻게 스트림 프로세스로 처리할 수 있게 된 것일까? 제이 크렙스는 모든 데이터를 로그로 바라보는 것에서 시작했다. 로그는 일반적인 로깅이 아닌 데이터의 집합을 뜻한다. 이 데이터는 지속적으로 추가가 가능하며 각 데이터에는 일정한 번호가 붙는다.
- 배치 데이터를 로그로 표현할 때는 각 시점의 배치 데이터의 변환 기록을 시간 순서대로 기록함으로써 각 시점의 모든 스냅샷 데이터를 저장하지 않고도 배치 데이터를 표현할 수 있게 되었다. 서비스에서 생성된 모든 데이터가 스피드 레이어에 들어오는 것을 감안하면 해당 레이어를 구성하는 데이터 플랫폼은 SPOF가 될 수 있으므로 반드시 내결함성과 장애 허용 특징을 지녀야 했다. 카프카의 파티션, 레코드, 오프셋은 로그의 데이터 플랫폼 구현체로 볼 수 있다.

`스트리밍 데이터 레이크`  
- 서빙 레이어를 제거한 아키텍처
- 스피드 레이어에서 데이터를 분석, 프로세싱, 저장함으로써 단일 진실 공급원(SSOT, single source of truth)이 되어 데이터의 중복, 비정합성과 같은 문제에서 벗어났다.
- 문제점
    - 자주 접근하지 않는 데이터를 굳이 비싼 자원(브로커의 메모리, 디스크)에 유지할 필요가 없다.
    - 그리고 데이터를 사용하는 고객이나 서비스 애플리케이션에서 카프카의 데이터를 쿼리할 수 있는 주변 데이터 플랫폼이 필요하다.
